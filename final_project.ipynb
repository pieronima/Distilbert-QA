{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38148dfc-b1cb-447c-a550-022d96f4b6db",
   "metadata": {},
   "source": [
    "# Transformers Question Answering (Huggingface method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d864e3e1-5910-42b9-86e3-82970b41df13",
   "metadata": {},
   "source": [
    "----\n",
    "### Importing main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adeba60a-b70e-49bb-a22e-e46f1846e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b4f25-857a-4587-821b-1a947adce843",
   "metadata": {},
   "source": [
    "### Downloading and managing Squad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55dd5d7f-458a-42e1-9e31-da1884511865",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('squad') #Creating squad directory locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31459104-f856-46f1-be08-a1102339085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/' #squad URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e45df3ab-f922-4ca7-8433-0c77d941c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a95adc8-21d8-4dfe-a919-9df080dd3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading train and dev from Squad dataset\n",
    "\n",
    "for file in ['train-v2.0.json', 'dev-v2.0.json']:\n",
    "    res = requests.get(f'{url}{file}') \n",
    "    with open(f'squad/{file}', 'wb') as f:\n",
    "        for chunk in res.iter_content(chunk_size=4):\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a45781-b489-4ae8-9e9c-30b5c26cec59",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31b786ba-c9fe-46c1-b09b-36db61ccac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba23485a-2ba1-479e-8f00-17f3eaeb8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting contexts, questions and answers from squad dataset\n",
    "\n",
    "def read_squad(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    \n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa[access]:\n",
    "                    contexts.append(context)\n",
    "                    questions .append(question)\n",
    "                    answers.append(answer)\n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fd353e5-856e-4810-9ab2-35e0240b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting contexts, questions and answers from train and validation datasets\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a58161-161f-489b-b30a-5802721e6c34",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3211899444.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    train_contexts[]\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Visualizing what data looks like\n",
    "\n",
    "train_contexts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5004f81-58b0-42e8-850d-5807fdfeb43f",
   "metadata": {},
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca71167a-13c7-431e-83a3-8723eeab6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing distilbert tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "357d404a-bb29-4593-a582-cb23fb4bbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing questions and context for both train and val datasets\n",
    "\n",
    "train_encodings = tokenizer(train_questions, train_contexts, return_offsets_mapping=True, truncation=\"only_second\", padding=True)\n",
    "val_encodings = tokenizer(val_questions, val_contexts, return_offsets_mapping=True, truncation=\"only_second\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce9ebac4-b5d5-4951-a018-33c2dd3448c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizing keys from dictionary\n",
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60fb0048-efb8-40ec-9f92-dcaf5ede9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting offset mapping from both train and val datasets\n",
    "\n",
    "train_offset_mapping = train_encodings.pop(\"offset_mapping\")\n",
    "val_offset_mapping = val_encodings.pop(\"offset_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b4e79f7-a388-4d6d-8471-c7b457623f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds start and end positions to the tokenized text to prepare it for finetune\n",
    "\n",
    "def add_token_positions(encodings, answers, offset_mapping):\n",
    "    answer = answers\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"]\n",
    "        end_char = answer[\"answer_start\"] + len(answer[\"text\"])\n",
    "        sequence_ids = encodings.sequence_ids(i)\n",
    "        \n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx+=1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx+= 1\n",
    "        context_end = idx - 1\n",
    "        \n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            \n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "            \n",
    "    encodings.update({\n",
    "        'start_positions' : start_positions,\n",
    "        'end_positions' : end_positions   \n",
    "    })\n",
    "\n",
    "add_token_positions(train_encodings, train_answers, train_offset_mapping)\n",
    "add_token_positions(val_encodings, val_answers, val_offset_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e278a3b7-e846-483f-b935-51dc4bf55706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking keys again to make sure start and end positions have been properly added\n",
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f2169b-d131-425a-b469-09905c36828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates datasets from a dictionary\n",
    "\n",
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self,idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da0e0d63-4caa-40d7-85ce-d4b60a50c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848dd2d-86e2-4557-8a2c-6553d83956e8",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d856593b-d383-4b42-94a4-6c071448be2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Importing distilbert model\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1892f8aa-709c-41cc-ace7-71e4a08696ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed62f824-11e6-4cb5-9cf9-a8626cff8d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking cuda is available for training\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d34a33d6-cbd7-4de3-a062-bdea1a479f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Declaring device, model and optimizer for training and setting model to train mode.\n",
    "\n",
    "device = torch.device('cuda') \n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5288fc71-7af3-48eb-a8bc-da385a85c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training settings\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0a70029-359f-465b-b84d-1153b735ddf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8145/8145 [53:59<00:00,  2.51it/s, loss=1.13] \n",
      "Epoch 1: 100%|██████████| 8145/8145 [53:31<00:00,  2.54it/s, loss=0.61] \n",
      "Epoch 2: 100%|██████████| 8145/8145 [53:35<00:00,  2.53it/s, loss=0.568] \n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "\n",
    "for epoch in range(3):  #Change epoch by changing range value\n",
    "    loop = tqdm(train_loader, leave=True) #Loading bar\n",
    "    for batch in loop:\n",
    "        optim.zero_grad() \n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        \n",
    "        #Calculating loss\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        #Printing loss\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7296e8cd-099c-4d9b-9bd3-a76e2062daba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/distilbert-custom-huggingface\\\\tokenizer_config.json',\n",
       " 'model/distilbert-custom-huggingface\\\\special_tokens_map.json',\n",
       " 'model/distilbert-custom-huggingface\\\\vocab.txt',\n",
       " 'model/distilbert-custom-huggingface\\\\added_tokens.json',\n",
       " 'model/distilbert-custom-huggingface\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving model and tokenizer\n",
    "\n",
    "model_path = 'model/distilbert-custom-huggingface'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7564c46-a372-437d-b9da-bcabb2b83569",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56dbf048-8a29-46e4-8f31-7d7e7147f1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing custom model from local PC\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('model/distilbert-custom-huggingface')\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('model/distilbert-custom-huggingface')\n",
    "\n",
    "#Setting model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c781a87-f3f3-4caa-9ddc-d9387558ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [03:52<00:00,  7.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Evaluating model\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "acc = []\n",
    "\n",
    "#Loading Bar\n",
    "loop = tqdm(val_loader, leave=True)\n",
    "for batch in loop:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        #Calculating predicted values\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        \n",
    "        #Calculating accuracy of model\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8c04e30-ca76-493e-88d6-fde6b51f825f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6082888719512195"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc)/len(acc) # Total Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cacc3f4e-dda7-4b42-94bc-8e170fd85711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([173, 173, 173, 173,  11,  34,  62, 111], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_true #Expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69792877-f4b1-46e0-9ba5-867e4387e559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 82,  82, 193, 186,  11,  33,  61, 110], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_pred #Predicted Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ede8e3-8970-4cae-83db-f6971c5464ca",
   "metadata": {},
   "source": [
    "## Running the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b5e421-34af-41f2-896b-266e9a600788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing ucstom model from local PC\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('model/distilbert-custom-huggingface')#replace with model directory\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('model/distilbert-custom-huggingface')#replace with model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c7fb94-bf32-4984-b04c-e1b35b02a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d191d6c-9df9-4a27-b88e-ce5d4376bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing model for custom question answering\n",
    "question_answerer = pipeline(\"question-answering\", \n",
    "                             model = AutoModelForQuestionAnswering.from_pretrained('model/distilbert-custom-huggingface'), #replace with model directory\n",
    "                             tokenizer = AutoTokenizer.from_pretrained('model/distilbert-custom-huggingface')) #replace with model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "938f2fc0-27b9-4c7f-a359-ebb8af55d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5154f0fb-ec02-484f-b286-705b18288c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring canvas and title\n",
    "root = tk.Tk()\n",
    "root.geometry(\"800x500\")\n",
    "root.title(\"Bert Question Answering\")\n",
    "\n",
    "#Define styling\n",
    "\n",
    "style = ttk.Style(root)\n",
    "style.theme_use(\"clam\")\n",
    "\n",
    "\n",
    "\n",
    "#Model input/output \n",
    "def Take_input():\n",
    "    context = textbox.get(\"1.0\", \"end-1c\")\n",
    "    question = textbox2.get(\"1.0\", \"end-1c\")\n",
    "    \n",
    "    final_answer = question_answerer(question=question, context=context)\n",
    "    \n",
    "    textbox3.delete(1.0,tk.END)\n",
    "    textbox3.insert(tk.END, final_answer['answer'])\n",
    "\n",
    "    \n",
    "#GUI objects\n",
    "\n",
    "##Context label\n",
    "label = tk.Label(root, text=\"Context\", font=('Arial',11))\n",
    "label.pack(padx=10, pady=10, anchor=\"w\")\n",
    "\n",
    "##Context textbox\n",
    "textbox = tk.Text(root, height=4, font=('Arial',10))\n",
    "textbox.pack(padx=10, pady=10, anchor=\"w\", expand=True, fill=tk.BOTH)\n",
    "\n",
    "##Question label\n",
    "label2 = tk.Label(root, text=\"Question\", font=('Arial',11))\n",
    "label2.pack(padx=10, pady=10, anchor=\"w\")\n",
    "\n",
    "\n",
    "##Question textbox\n",
    "textbox2 = tk.Text(root, height=2, font=('Arial',10))\n",
    "textbox2.pack(padx=10, pady=10, anchor=\"w\", expand=True, fill=tk.BOTH)\n",
    "\n",
    "#Enter button\n",
    "button = tk.Button(root, text=\"Enter\", height=2, width=11, font=('Arial', 10) , command=lambda:Take_input())\n",
    "button.pack(padx=10, pady=10,  anchor=\"e\")\n",
    "\n",
    "##Answer label\n",
    "label3 = tk.Label(root, text=\"Answer\", font=('Arial',11))\n",
    "label3.pack(padx=10, pady=10, anchor=\"w\")\n",
    "\n",
    "#Answer textbox\n",
    "textbox3 = tk.Text(root, height=3, font=('Arial',10))\n",
    "textbox3.pack(padx=10, pady=10, anchor=\"w\", expand=True, fill=tk.BOTH)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1edd8-40b4-4a00-8375-891a53e8ad83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed7d10-6431-4d84-be69-136124a898f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
